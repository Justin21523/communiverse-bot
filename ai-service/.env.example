# ===== Service =====
SERVICE_NAME=communiverse-ai-service
SERVICE_VERSION=2.0.0
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=info

# ===== Models / Cache / Device =====
LLM_MODEL=deepseek
VLM_MODEL=qwen-vl
EMBED_MODEL=bge-m3
MODEL_CACHE_DIR=/mnt/c/AI_LLM_projects/ai_warehouse/models
DEVICE=cuda
HF_TOKEN=
HF_HOME=/mnt/c/AI_LLM_projects/ai_warehouse/models/huggingface
TRANSFORMERS_CACHE=/mnt/c/AI_LLM_projects/ai_warehouse/models/transformers
SENTENCE_TRANSFORMERS_HOME=/mnt/c/AI_LLM_projects/ai_warehouse/models/sentence-transformers

# ===== CORS / Preload =====
CORS_ORIGINS=["http://localhost:3000","http://localhost:8080"]
PRELOAD_LLM=true
PRELOAD_VLM=false
PRELOAD_EMBEDDINGS=false

# ===== Hardware =====
USE_8BIT=true
USE_4BIT=false
MAX_MEMORY_GB=

# ===== Generation Defaults =====
DEFAULT_MAX_TOKENS=2048
DEFAULT_TEMPERATURE=0.7
DEFAULT_TOP_P=0.9

# ===== Performance =====
MAX_BATCH_SIZE=8
MODEL_LOAD_TIMEOUT=300
GENERATION_TIMEOUT=60

# ===== API / Metrics =====
API_KEY=
METRICS_ENABLED=true
METRICS_PORT=9091

# ===== Rate Limiting (new scheme) =====
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# ===== Agent (consolidated) =====
AGENT_MAX_STEPS=10
AGENT_MAX_RETRIES=3
AGENT_TIMEOUT=60
AGENT_REASONING_ENABLED=true
AGENT_PARALLEL_TOOLS=true

# ===== Vector / RAG / BM25 / Hybrid =====
VECTOR_DB_PATH=/mnt/c/AI_LLM_projects/ai_warehouse/vector_db
VECTOR_DIM=1024
BM25_INDEX_PATH=/mnt/c/AI_LLM_projects/ai_warehouse/bm25_index
# 可選：如果你把下列項目也改成 Field(..., env="...") 才會生效
VECTOR_METRIC=cosine
BM25_K1=1.2
BM25_B=0.75
HYBRID_ALPHA=0.5
RAG_TOP_K=10
RAG_MMR_SCORE=0.7
RAG_RERANK=false
RAG_RERANK_MODEL=BAAI/bge-reranker-base

# ===== Story (如有使用) =====
STORY_DB_PATH=/mnt/c/AI_LLM_projects/ai_warehouse/stories
STORY_SEARCH_ENABLED=false
STORY_CONTEXT_WINDOW=10
STORY_SAVE_INTERVAL=1

# ===== MongoDB =====
MONGODB_URI=mongodb://localhost:27017
MONGODB_DB=communiverse_bot

# ===== Fine-tuning =====
FINETUNE_OUTPUT_DIR=/mnt/c/AI_LLM_projects/ai_warehouse/fine_tuned_models
TRAINING_DATA_DIR=/mnt/c/AI_LLM_projects/ai_warehouse/training_data
FINETUNE_CHECKPOINT_DIR=/mnt/c/AI_LLM_projects/ai_warehouse/checkpoints
# 可選：若你把下列也加上 env=
FINETUNE_BATCH_SIZE=4
FINETUNE_LEARNING_RATE=2e-4
FINETUNE_EPOCHS=3
FINETUNE_WARMUP_STEPS=100

# ===== LoRA (若你用 env 控制) =====
LORA_R=8
LORA_ALPHA=32
LORA_DROPOUT=0.05
LORA_TARGET_MODULES=q_proj,v_proj

# ===== Dataset / Token =====
HFX_TOKEN=
DATASET_CACHE_DIR=/mnt/c/AI_LLM_projects/ai_warehouse/datasets
HF_DATASETS_CACHE=/mnt/c/AI_LLM_projects/ai_warehouse/datasets/huggingface

# ===== Web Search (consolidated) =====
WEB_SEARCH_ENABLED=true
WEB_SEARCH_API_KEY=
WEB_SEARCH_MAX_RESULTS=5
WEB_SEARCH_TIMEOUT=10
BRAVE_API_KEY=
